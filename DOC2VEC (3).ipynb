{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l241ZOY2opcs",
        "outputId": "f78d8220-68fc-4e48-96ad-c79da9efa703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "import nltk\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oY8_b_JuSD1"
      },
      "outputs": [],
      "source": [
        "def preprocess_java_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        java_code = file.read()\n",
        "    # Tokenize the Java code\n",
        "    tokens = word_tokenize(java_code)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWn1XEN0BUQh",
        "outputId": "fdaa3140-8e1d-470d-c0ba-e4d1e458de48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeK_FpOpuYsF"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6RgP9KORfri"
      },
      "source": [
        "Infer to vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJlvtN7sTAjL",
        "outputId": "6f2614d6-87b8-44ab-eeb6-a7972515a6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Try using different encodings\n",
        "try:\n",
        "    model = gensim.models.Doc2Vec.load(\"/content/drive/MyDrive/ATBM/doc2vec/doc2vec_model\", mmap='r')\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Error loading model:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdc_k_uCTEPC"
      },
      "outputs": [],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAt20NuBB7lB",
        "outputId": "7a22c435-556b-48fd-e46b-a2c751e6447e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3256\n",
            "3256\n",
            "897\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "# gexf_folder = '/content/drive/MyDrive/ATBM/Tung/fcg_benign'\n",
        "# java_folder = '/content/drive/MyDrive/ATBM/Tung/java_benign'\n",
        "\n",
        "gexf_folder = '/content/drive/MyDrive/ATBM/Tung/BTL_ATBM_MINH/op_fcg_benign_final'\n",
        "java_folder = '/content/drive/MyDrive/ATBM/Tung/BTL_ATBM_MINH/op_java_benign_final'\n",
        "output_feat_folder = '/content/drive/MyDrive/ATBM/Tung/vec_benign'\n",
        "\n",
        "print(len(os.listdir(gexf_folder)))\n",
        "print(len(os.listdir(java_folder)))\n",
        "print(len(os.listdir(output_feat_folder)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output_feat_folder = [\"fhiasdhfisadf()\", \"ifbasidbf\"]\n",
        "for filename in os.listdir(output_feat_folder):\n",
        "  if \"(\" in filename:\n",
        "    print(filename)\n",
        "for filename in os.listdir(output_feat_folder):\n",
        "  if \"(\" in filename:\n",
        "    os.remove(output_feat_folder+\"/\"+filename)"
      ],
      "metadata": {
        "id": "Axn44H9F5MJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgw-f4-1Pv8T"
      },
      "source": [
        "## Count fcg file that has java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75MKDgWFPucn"
      },
      "outputs": [],
      "source": [
        "# def get_fcgs_has_java(gexf_folder, java_folder):\n",
        "#   cnt = 0\n",
        "#   a = []\n",
        "#   for gexf_filename in os.listdir(gexf_folder):\n",
        "#     if gexf_filename.endswith('.gexf'):\n",
        "#       apk_id = gexf_filename[:-5]\n",
        "#       java_filepath = os.path.join(java_folder, f'{apk_id}.txt')\n",
        "#       if(f'{apk_id}.txt' in os.listdir(java_folder)):\n",
        "#         cnt+=1\n",
        "#         a.append(apk_id)\n",
        "#   return a\n",
        "# fcgs_has_java = get_fcgs_has_java(gexf_folder, java_folder)\n",
        "# print(len(fcgs_has_java))\n",
        "\n",
        "# left = []\n",
        "# for x in fcgs_has_java:\n",
        "#   if(f'{x}.txt') not in output_feat_folder:\n",
        "#     left.append(x)\n",
        "# print(len(left))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovbkSsgF_5U8"
      },
      "source": [
        "## Count file in folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNH8Pucgzo1E",
        "outputId": "2d83edb2-f26c-43be-e2aa-63e850c0005e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files in folder op_fcg_benign_final: 3256\n",
            "Number of files in folder op_java_benign_final: 3256\n",
            "Number of files in folder vec_benign: 887\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_files(folder_path):\n",
        "  try:\n",
        "    entries = os.scandir(folder_path)\n",
        "    files = [entry for entry in entries if entry.is_file()]\n",
        "    return len(files)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Folder not found: {folder_path}\")\n",
        "    return 0  # Return 0 if folder doesn't exist\n",
        "\n",
        "# Example usage (replace with your actual folder path)\n",
        "print(f\"Number of files in folder {gexf_folder.split('/')[-1]}: {count_files(gexf_folder)}\")\n",
        "print(f\"Number of files in folder {java_folder.split('/')[-1]}: {count_files(java_folder)}\")\n",
        "print(f\"Number of files in folder {output_feat_folder.split('/')[-1]}: {count_files(output_feat_folder)}\")\n",
        "# print(f\"Number of files in fcgs_has_java: {len(fcgs_has_java)}\")\n",
        "#828\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qbUb1VBAwgp",
        "outputId": "f0710ee7-7ec4-4472-dc5b-90a1bfe5d698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2370\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "gexf_files = [file[:-5] for file in os.listdir(gexf_folder) if file.endswith('.gexf')]\n",
        "txt_files = [file[:-4] for file in os.listdir(output_feat_folder) if file.endswith('.txt')]\n",
        "\n",
        "gexf_files_set = set(gexf_files)\n",
        "txt_files_set = set(txt_files)\n",
        "\n",
        "unique_gexf_files = gexf_files_set - txt_files_set\n",
        "print(len(unique_gexf_files))\n",
        "print('CE5119808A8F2138609B5322FBCBAD8DA8E9ADEEFE36004BFE67214C60DD759D' in unique_gexf_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLaHxOB0tYQa",
        "outputId": "4d1e2cb4-b4d6-4c55-ae7e-74b1bb16fe51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "HAS EMBEDDED!\n",
            "Running FD67C11BD87615DFA59C44E3C0D139B3E09386B6FA1F291EA327A5527B35040D.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/FD67C11BD87615DFA59C44E3C0D139B3E09386B6FA1F291EA327A5527B35040D.txt\n",
            "DONE FD67C11BD87615DFA59C44E3C0D139B3E09386B6FA1F291EA327A5527B35040D.gexf\n",
            "Running FDFF02F6A2DE355BFD64D58F3C03B96E9B97881643A4EEC7CE4616607BE67C83.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/FDFF02F6A2DE355BFD64D58F3C03B96E9B97881643A4EEC7CE4616607BE67C83.txt\n",
            "DONE FDFF02F6A2DE355BFD64D58F3C03B96E9B97881643A4EEC7CE4616607BE67C83.gexf\n",
            "Running FF481FAEFDFA0C30FBB04C4A10739CFFAD615AD6AEC9F928AC50F59BD7A2FA7A.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/FF481FAEFDFA0C30FBB04C4A10739CFFAD615AD6AEC9F928AC50F59BD7A2FA7A.txt\n",
            "DONE FF481FAEFDFA0C30FBB04C4A10739CFFAD615AD6AEC9F928AC50F59BD7A2FA7A.gexf\n",
            "Running FFBB6BB42BE11C7B18DC666562BBF822A8D56CF695D57905DCD7140FF8749982.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/FFBB6BB42BE11C7B18DC666562BBF822A8D56CF695D57905DCD7140FF8749982.txt\n",
            "DONE FFBB6BB42BE11C7B18DC666562BBF822A8D56CF695D57905DCD7140FF8749982.gexf\n",
            "Running 0065D3E4AD273C02119D630E1047BA0FB756E7F0ED8ED83EC6410997B5480D45.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/0065D3E4AD273C02119D630E1047BA0FB756E7F0ED8ED83EC6410997B5480D45.txt\n",
            "DONE 0065D3E4AD273C02119D630E1047BA0FB756E7F0ED8ED83EC6410997B5480D45.gexf\n",
            "Running 000040A9B9EBC7FCD250B9A115C015114BCD77E10A94D151438864E6F111A631.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/000040A9B9EBC7FCD250B9A115C015114BCD77E10A94D151438864E6F111A631.txt\n",
            "DONE 000040A9B9EBC7FCD250B9A115C015114BCD77E10A94D151438864E6F111A631.gexf\n",
            "Running 00CC5A66573BE9D5F2B15FB2C8FD72A5F2CFB6DCFB26A14D16E54F7B342826CF.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/00CC5A66573BE9D5F2B15FB2C8FD72A5F2CFB6DCFB26A14D16E54F7B342826CF.txt\n",
            "DONE 00CC5A66573BE9D5F2B15FB2C8FD72A5F2CFB6DCFB26A14D16E54F7B342826CF.gexf\n",
            "Running 00A0E788B41DE7218B086CB0AD71231C3B553E3C193AB3D800500C2BB836A170.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/00A0E788B41DE7218B086CB0AD71231C3B553E3C193AB3D800500C2BB836A170.txt\n",
            "DONE 00A0E788B41DE7218B086CB0AD71231C3B553E3C193AB3D800500C2BB836A170.gexf\n",
            "Running 00F4BC5C456B4A88C4FE07BC995AA97619A0F7AAB8F52090FE067473DF35B951.gexf\n",
            "/content/drive/MyDrive/ATBM/Tung/vec_benign/00F4BC5C456B4A88C4FE07BC995AA97619A0F7AAB8F52090FE067473DF35B951.txt\n",
            "DONE 00F4BC5C456B4A88C4FE07BC995AA97619A0F7AAB8F52090FE067473DF35B951.gexf\n",
            "Running 01A8285F9F4213B81927D592E3848338DB246DFAC8957547B308E939CFF59394.gexf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import networkx as nx\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "def extract_and_embed_functions(gexf_folder, java_folder, doc2vec_model, output_feat_folder):\n",
        "\n",
        "  # Load the Doc2Vec model\n",
        "  model = doc2vec_model\n",
        "  # Iterate over GEXF files\n",
        "  for gexf_filename in os.listdir(gexf_folder):\n",
        "    if gexf_filename.endswith('.gexf'):\n",
        "      apk_id = gexf_filename[:-5]  # Extract APK ID from filename (assuming format)\n",
        "      if(apk_id not in fcgs_has_java):\n",
        "        continue\n",
        "      if(apk_id not in unique_gexf_files):\n",
        "        print(\"HAS EMBEDDED!\")\n",
        "        continue\n",
        "      # Construct file paths\n",
        "      gexf_filepath = os.path.join(gexf_folder, gexf_filename)\n",
        "      java_filepath = os.path.join(java_folder, f'{apk_id}.txt')\n",
        "      output_feat_folder_filepath = os.path.join(output_feat_folder, f'{apk_id}.txt')\n",
        "\n",
        "      # Load the GEXF graph\n",
        "      graph = nx.read_gexf(gexf_filepath)\n",
        "      function_names = [node for node in graph.nodes()]\n",
        "\n",
        "      # Read Java content\n",
        "      try:\n",
        "          with open(java_filepath, 'r') as file:\n",
        "              java_content = file.read()\n",
        "      except FileNotFoundError:\n",
        "          print(f\"Java file not found: {java_filepath}\")\n",
        "          continue  # Skip to next iteration if Java file is missing\n",
        "\n",
        "      print(\"Running \" + gexf_filename)\n",
        "      # Extract and embed function content\n",
        "      fc_str = []\n",
        "      for function_name in function_names:\n",
        "          parameters, body = extract_function_content(java_content, function_name)\n",
        "          if parameters is not None and body is not None:\n",
        "              processed_fc = f'{function_name}({parameters})' + '{' + f'{body}' + '}'\n",
        "          else:\n",
        "              processed_fc = f'{function_name}({parameters})' + '{}'\n",
        "          fc_str.append(processed_fc)\n",
        "\n",
        "      # Preprocess if necessary (using NLTK for example)\n",
        "      from nltk import word_tokenize  # Import NLTK library for tokenization\n",
        "\n",
        "      preprocessed_strings = []\n",
        "      for string in fc_str:\n",
        "          tokens = word_tokenize(string)\n",
        "          preprocessed_strings.append(tokens)\n",
        "\n",
        "      # Embed each string (using preprocessed strings)\n",
        "      string_vectors = []\n",
        "      for string in preprocessed_strings:\n",
        "          vector = model.infer_vector(string)  # Use infer_vector for unseen data\n",
        "          string_vectors.append(vector)\n",
        "\n",
        "      # Save FEATURE MATRIX to a text file (one vector per line)\n",
        "      try:\n",
        "          with open(output_feat_folder_filepath, 'w') as output_file:\n",
        "              print(output_feat_folder_filepath)\n",
        "              for vector in string_vectors:\n",
        "                  output_file.write(str(vector) + '\\n')  # Write each vector on a new line\n",
        "          print(\"DONE \"+gexf_filename)\n",
        "      except IOError:\n",
        "          print(f\"Error saving output to: {output_feat_folder_filepath}\")\n",
        "\n",
        "extract_and_embed_functions(gexf_folder, java_folder, model, output_feat_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n32K4S9_nAS"
      },
      "source": [
        "ZIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN6pIdNsMPNG"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the source folder and output zip file\n",
        "folder = 'benign_vec'  # Replace with the path and name of the zip file (without .zip)\n",
        "\n",
        "# Create a zip file from the folder\n",
        "shutil.make_archive(folder, 'zip', folder)\n",
        "\n",
        "print(f'Folder {folder} has been zipped to {folder}.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw7eob7q1YmS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}